{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmGqbsINsIlf"
      },
      "outputs": [],
      "source": [
        "#Install Transformers library to run this notebook.\n",
        "\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "BsBsLZbchzLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 1 - An Introduction to Inference Pipelines**"
      ],
      "metadata": {
        "id": "TMMrWPK-USsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 - Sentiment Analysis**"
      ],
      "metadata": {
        "id": "KT7t8sEhDjZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The call to pipeline() specifies the task and the model\n",
        "\n",
        "# The task specification is mandatory. In this case, we are creating a pipeline for sentiment analysis\n",
        "# Model specification is optional. By default, the pipeline selects a particular pretrained model\n",
        "# that has been fine-tuned for sentiment analysis in English: DistilBERT base uncased finetuned SST-2\n",
        "# https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
        "\n",
        "\n",
        "MSA1 = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "MSA1(\"I've been waiting for a HuggingFace course my whole life.\")"
      ],
      "metadata": {
        "id": "7bxrhYHFhfit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try  model MSA1 with several other sentences\n",
        "\n",
        "str1 = ['I hate this so much!', 'Your support team is useless',\n",
        "       'Disliking watercraft is not really my thing.', 'I would really truly love going out in this weather!',\n",
        "       'You should see their decadent dessert menu.',  'I love my mobile but would not recommend it to any of my colleagues.']\n",
        "\n",
        "MSA1(str1)"
      ],
      "metadata": {
        "id": "22o4bEqJhwze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't forget that language models can be biased and unfair.\n",
        "# Most of the bias comes from training data\n",
        "\n",
        "str2 = ['I am from Portugal.', 'I am from India.', 'I am from Iraq.']\n",
        "\n",
        "MSA1(str2)"
      ],
      "metadata": {
        "id": "SgBCIcLFCgTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You can change some of the sentences above and check if the analysis is different**"
      ],
      "metadata": {
        "id": "k04ij6SyG0KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can specify another model as a parameter:\n",
        "\n",
        "# The bertweet-sentiment-analysis model was fine tuned for sentiment analysis (the base model is BERTweet, a RoBERTa model trained on English tweets)\n",
        "# https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis\n",
        "\n",
        "# Just add an additional parameter (model) to the pipeline function\n",
        "\n",
        "MSA2 = pipeline('sentiment-analysis', model='finiteautomata/bertweet-base-sentiment-analysis')"
      ],
      "metadata": {
        "id": "Q4qPYC90llJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRY\n",
        "\n",
        "# Apply the new model on the previous sentences and compare performance\n",
        "\n",
        "MSA2(str1)\n"
      ],
      "metadata": {
        "id": "iKnqH8HjnZKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 - Text Generation**"
      ],
      "metadata": {
        "id": "nkuEfw5gDo2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Generation task: https://huggingface.co/tasks/text-generation\n",
        "\n",
        "Gen1 = pipeline('text-generation')\n",
        "\n",
        "Gen1('In this course, we will teach you how to',  max_length=100)"
      ],
      "metadata": {
        "id": "eCLvmp1TDdeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try with different prompts\n",
        "\n",
        "prompt = 'My name is Carlos and'\n",
        "\n",
        "Gen1(prompt,  max_length=100)"
      ],
      "metadata": {
        "id": "TAHU9sPPeOOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRY\n",
        "\n",
        " # 2. Select another model for this task, create pipeline Gen2 and compare outputs\n",
        " # Check in Hugging Face for other models can be applied to this\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e2TUhEeKumVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 - Translation**"
      ],
      "metadata": {
        "id": "wT1ORSDjJCMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation task: https://huggingface.co/tasks/translation\n",
        "\n",
        "# There are models that can handle several languages. This one can translate from many different languages to English\n",
        "# https://huggingface.co/Helsinki-NLP/opus-mt-mul-en\n",
        "\n",
        "\n",
        "T1 = pipeline('translation', model='Helsinki-NLP/opus-mt-mul-en')\n",
        "\n",
        "T1(['Olá.', 'Boa noite.', 'A capital de Portugal é Lisboa'])\n"
      ],
      "metadata": {
        "id": "i4Mg59YBMHts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T1(['Hola.', 'Buenas noches.', 'Hoy no llueve.'])\n"
      ],
      "metadata": {
        "id": "VFSX3a88JUMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T1(['Näkemiin.', 'Anteeksi, en puhu suomea.', 'Yksi kieli ei koskaan riitä.'])\n"
      ],
      "metadata": {
        "id": "6kzg2D8xJhRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}